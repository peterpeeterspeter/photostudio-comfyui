{
  "last_node_id": 12,
  "nodes": {
    "1": {
      "class_type": "LoadImage",
      "inputs": {
        "image": "test_garment.jpg",
        "upload": "image"
      },
      "pos": [100, 100]
    },
    "2": {
      "class_type": "RMBGNode",
      "inputs": {
        "image": ["1", 0],
        "threshold": 0.30,
        "mask_blur": 3,
        "post_dilate": 8,
        "output_mode": "both",
        "model_name": "u2net"
      },
      "pos": [400, 100]
    },
    "3": {
      "class_type": "CannyEdgePreprocessor",
      "inputs": {
        "image": ["2", 0],
        "low_threshold": 120,
        "high_threshold": 240,
        "l2gradient": false
      },
      "pos": [700, 100]
    },
    "4": {
      "class_type": "ControlNetLoader",
      "inputs": {
        "control_net_name": "control_v11p_sd15_canny.pth"
      },
      "pos": [100, 300]
    },
    "5": {
      "class_type": "CheckpointLoaderSimple",
      "inputs": {
        "ckpt_name": "sd_xl_base_1.0.safetensors"
      },
      "pos": [100, 500]
    },
    "6": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "Professional ghost mannequin product photo, invisible mannequin effect, clean white background, studio lighting, commercial product photography, high quality, sharp details, IMG_2094.CR2",
        "clip": ["5", 1]
      },
      "pos": [400, 300]
    },
    "7": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "text": "low quality, blurry, distorted, visible mannequin, background patterns, harsh shadows, oversaturated colors, cropped edges, halo, fringing, color bleed",
        "clip": ["5", 1]
      },
      "pos": [400, 500]
    },
    "8": {
      "class_type": "ControlNetApply",
      "inputs": {
        "conditioning": ["6", 0],
        "control_net": ["4", 0],
        "image": ["3", 0],
        "strength": 0.9,
        "start_percent": 0.0,
        "end_percent": 1.0
      },
      "pos": [700, 300]
    },
    "9": {
      "class_type": "EmptyLatentImage",
      "inputs": {
        "width": 1024,
        "height": 1024,
        "batch_size": 1
      },
      "pos": [700, 500]
    },
    "10": {
      "class_type": "KSampler",
      "inputs": {
        "seed": 123456,
        "steps": 24,
        "cfg": 6.5,
        "sampler_name": "dpmpp_2m_karras",
        "scheduler": "karras",
        "positive": ["8", 0],
        "negative": ["7", 0],
        "model": ["5", 0],
        "latent_image": ["9", 0]
      },
      "pos": [1000, 400]
    },
    "11": {
      "class_type": "VAEDecode",
      "inputs": {
        "samples": ["10", 0],
        "vae": ["5", 2]
      },
      "pos": [1300, 400]
    },
    "12": {
      "class_type": "SaveImage",
      "inputs": {
        "filename_prefix": "ghost_mvp_",
        "images": ["11", 0]
      },
      "pos": [1600, 400]
    }
  },
  "extra": {
    "ds": {
      "scale": 0.8,
      "offset": [0, 0]
    }
  },
  "version": 0.4
}
